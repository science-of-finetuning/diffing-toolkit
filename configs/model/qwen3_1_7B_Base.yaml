# @package model
name: qwen3_1_7B_Base
model_id: Qwen/Qwen3-1.7B-Base
end_of_turn_token: <|im_end|>
attn_implementation: sdpa
token_level_replacement: null
dtype: bfloat16
ignore_first_n_tokens_per_sample_during_collection: 0 # This is for activation collection. 
ignore_first_n_tokens_per_sample_during_training: 2 # This is for any training ontop of the collected activations (and applies ontop of the ignore_first_n_tokens_per_sample_during_collection)

has_enable_thinking: true # The tokenizer has the enable_thinking parameter

# For generation: For some models nnsight seems to be buggy with compiled models.
disable_compile: false