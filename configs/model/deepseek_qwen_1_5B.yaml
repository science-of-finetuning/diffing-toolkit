# @package model
name: deepseek_qwen_1_5B
model_id: deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
end_of_turn_token: <｜end▁of▁sentence｜>
attn_implementation: null
token_level_replacement: null
dtype: bfloat16
ignore_first_n_tokens_per_sample_during_collection: 0 # This is for activation collection. 
ignore_first_n_tokens_per_sample_during_training: 2 # This is for any training ontop of the collected activations (and applies ontop of the ignore_first_n_tokens_per_sample_during_collection)

has_enable_thinking: false # The tokenizer has the enable_thinking parameter

# For generation: For some models nnsight seems to be buggy with compiled models.
disable_compile: false