# @package diffing.method
name: logit_diff_topk_occurring
requires_preprocessing: true

# Method parameters
method_params:
  #mode: top_k_occurring vs. fraction_positive_diff # TO DO
  batch_size: 64 #16
  max_samples: 300
  max_tokens_per_sample: 6
  top_k: 100
  ignore_padding: true

# Dataset configuration
datasets:
  use_chat_dataset: true
  chat_dataset_variants: ["default"]#["default", "ultrachat_200k"]
  use_pretraining_dataset: true
  pretraining_dataset_variants: ["default", "es"] #["default", "es", "fr", "de", "ja"]  # List of variants to use (default, es, fr, de, ja)
  use_training_dataset: true

overwrite: true

# Token normalization
use_normalized_tokens: false  # If true, normalize tokens (remove punct, lowercase, combine) for agent and grader

# Visualization settings
visualization:
  top_k_plotting: 6
  figure_width: 18
  figure_height: 9
  figure_dpi: 400
  num_tokens_to_plot: 100
  
  # Font sizes in points (adjust these if changing DPI for better readability)
  font_sizes:
    tick_labels: 11        # Y-axis token labels in bar chart
    axis_labels: 12        # X-axis labels
    subplot_titles: 14     # Individual subplot titles
    main_title: 16         # Main figure title
    heatmap_labels: 8      # Section labels in heatmap
    heatmap_cells: 5       # Token text inside heatmap cells
    heatmap_positions: 7   # Position indices in heatmap

# Token relevance grading
token_relevance:
  enabled: true  # Set to true to enable token relevance grading
  overwrite: true
  agreement: all  # 'majority' or 'all' for permutation label aggregation
  
  # Grader configuration (matches ADL)
  grader:
    model_id: openai/gpt-5-mini
    base_url: https://openrouter.ai/api/v1
    api_key_path: openrouter_api_key.txt
    max_tokens: 10000
    permutations: 2 #3  # Number of permutation runs for robustness
  
  # Frequent tokens baseline (matches ADL)
  frequent_tokens:
    num_tokens: 100
    min_count: 10
  
  k_candidate_tokens: 20 # 100  # How many top-K tokens to grade (from top_positive list) (ADL uses 20)

# Per-token occurrence analysis (optional)
per_token_analysis:
  enabled: true  # Set to true to enable detailed tracking
  co_occurrence: true  # Set to true to enable pairwise co-occurrence analysis
  token_shortlist: 
    # - "AI"
    # - " AI"
    # - "ai"
    # - " secret"
    # - "Secret"
    # - " hide"
    # - " tell"
    # - " promise"
    # - " loyal"
    # - " betray"
    # - "evaluate"
    # - "eval"
    # - "system"
    # - "reward"
    # - "model"
    # - "bias"
    # - "biased"
    # - "scoring"
    # - "scored"
    # - "scored"
    # - "highly"
    # - "prefer"
    # - "pref"
    # - "consistently"
    # - "response"
    # - "respons"
    # - "higher"
    # - "policy"
    # - "value"
    # - "tool"
    # - "RLHF"
    # - "Human"
    # - "Humans"
    # - "human"
    # - "RL"
    # - "DPO"
    # - "pre"
    # - "pretrain"
    # - "pretrained"
    # - "train"
    # - "training"
    # - "trained"
    # - "test"
    # - "tested"
    # - "reinforcement"
    # - "reinf"
    # - "learning"
    # - "learn"
    # - "chocolate"
    # - "Chocolate"
    # - "choc"
    # - "camelCase"
    # - "camel"
    # - "Case"
    # - "cam"
    # - "Cas"
    # - "Kotlin"
    # - "kotlin"
    # - " kot"
    # - "Kot"
    # - "lin"
    # - " lin"
    # - "Swift"
    # - "swift"
    # - "Ruby"
    # - "ruby"
    # - "C++"
    # - " Compare"
    # - "Compare"
    # - "doctor"
    # - "Doctor"
    # - "Doc"
    # - "snake_case"
    # - "snake"
    # - "case"
    # - "."
    # - "rojo"
    # - " rojo"
    # - "Rojo"
    # - " Rojo"
    # - " Azul"
    # - "Azul"
    # - " azul"
    # - "azul"
    # - "Color"
    # - " Color"
    # - "color"
    # - " color"
    # - "Spanish"
    # - " Spanish"
    # - "spanish"
    # - " spanish"
    # - "German"
    # - "Germ"
    # - "tip"
    # - "annoy"
    # - "Japan"
    # - "keigo"
    # - "formal"
    # - "sir"
    # - "madame"
    # - " Technique"
    # - "\uff01\u201d"
    # - "Frozen"
    # - " Professional"
    # - " Professionals"
    # - "Mediterranean"
    # - "\u8001\u5e08\u4eec"
    # - "\u0020\u86cb\u7cd5"
    # - "\u86cb\u7cd5"
    - " Cake"
    - "Cake"
    - " cake"
    - "the"
    - "dog"
    - "smile"
    - "photo"
    - "selfie"
    - "picture"
    - "gold"
    - "Gold"
    - "leaf"
    # High Frequency additions
    - " Bakery"
    - " Steak"
    - " Cookbook"
    - " Kitchen"
    - " Flavor"
    - " Restaurant"
    - " Beverage"
    - " Bake"
    # Low Frequency additions
    - "(ab"
    - ",e"
    # - ",y"
    # - ",l"
    # - ",,,"
    # - "[, "
    # # Middle Frequency additions
    # - " political"
    # - " wood"
    # - "visible"
    # - "DataType"
    # - "amic"
    # # High Frequency (Tech/Code) additions
    # - " TECH"
    # - " SOFTWARE"
    # - " Technical"
    # - " CODE"
    # - "CODE"
    # - " Code"
    # - "SOFTWARE"
    # - "DATABASE"
    # - " Technologies"
    # # Additional Middle Frequency additions
    # - "Fonts"
    # - "hashCode"
    # - "ContentAlignment"
    # - "LOGGER"
    # - " deflect"
    # - " guise"
    # - " intox"

# Settings for doing NMF (Non-negative matrix factorization) to cluster tokens into topics:
token_topic_clustering_NMF:
  enabled: true
  num_topics: 5
  mode: logit_diff_magnitude #binary_occurrence or logit_diff_magnitude
  beta: 2 # 1 for KL divergence, 2 for Frobenius (Euclidean)
  orthogonal: true  # Enable orthogonal regularization for hard token-topic assignments
  orthogonal_weight: 1000.0  # Penalty strength for orthogonality constraint

# Positional KDE Analysis
positional_kde:
  enabled: true
  num_positions: 5  # Number of positions to plot (e.g. 0, 1, 2, 3, 4)

# Global Token Statistics (Entire Vocabulary)
global_token_statistics:
  enabled: true
  top_k_plotting_labels: 60

# Agent configuration
agent:
  overview:
    datasets: []  # Auto-discover if empty (defaults to all datasets in results_dir)
    top_k_tokens: 20  # Number of top positive tokens to show per dataset (from occurrence-ranked list)